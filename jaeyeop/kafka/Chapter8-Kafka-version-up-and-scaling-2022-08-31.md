# Chapter8 Kafka Version Up and Scaling
## 8.1 카프카 버전 업그레이드를 위한 준비
- 카프카 버전 업그레이드 작업을 하기 전에 현재 내가 사용하고 있는 카프카 버전이 무엇인지를 확인
- 다음으로 업그레이드 버전을 정하고 카프카의 릴리스 노트 등을 살펴보면서 버전 업그레이드 시 문제가 될 만한 부분을 확인
- 카프카의 상위 버전은 클라이언트들의 하위 호환성을 갖고 있으므로 대부분 클라이언트 이슈는 없지만 전체적으로 카프카 릴리스 노트를 확인해야 한다.
- Semantic Versioning을 따른다.
    - Major.Minor.Patch
- 카프카의 버전 업그레이드 방법
    - 카프카 다운타임 허용
    - 카프카 다운타임 불가(운영환경은 대부분 이것)
        - 이 경우 Broker 한 대씩 Rolling Update를 진행한다.

## 8.2 주키퍼 의존성이 있는 카프카 롤링 업그레이드
- Example) Zookeeper 버전 Up X + Kafka 버전 UP O
    - Kafka 2.1 -> Kafka 2.6

### 8.2.1 최신 버전의 카프카 다운로드와 설정
- 카프카 다운로드는 모든 브로커에서 진행
- kafka -> /usr/local/kafka_2.12-2.1.0 링크가 걸려있는데 이걸 변경해줘야한다.
- server.properties를 2.1.0 -> 2.1.6으로 복사한다.cp kafka_2.12-2.1.0/config/server.properties kafka_2.12-2.1.6/config/server.properties 
    - inter.broker.protocol.version=2.1
    - log.message.format.vesion=2.1
    - 브로커 간의 내부 통신과 메시지 포맷을 2.1로 유지한다.
    - 브로커 설정 파일에 적용하지 않고 2.6 버전의 브로커를 실행한다면 이미 실행중인 2.1 버전 브로커들과 통신이 불가하다.
### 8.2.2 브로커 버전 업그레이드
- 브로커 버전 업그레이드는 한 대씩 순차적으로 진행
- 브로커를 종료하면, 종료된 브로커가 갖고 있던 파티션의 리더들이 다른 브로커로 변경된다.
- 카프카 클라이언트 내부적으로 재시도 로직이 있으므로 모든 클라이언트는 변경된 새로운 리더가 있는 브로커를 바라보게 된다.
- Kafka 심볼릭 링크를 2.6버전으로 변경한다.
    - rm -rf kafka
    - ln -sf kafka_2.12-2.6.0 kafka
- 브로커를 실행한다.
    - 카프카 버전은 2.6
    - 브로커 프로토콜 버전 2.1
    - 메시지 포맷 버전 2.1
- 토픽 상세보기 명령어를 통해 리플리케이션과 ISR이 잘 동작되는지 확인가능함.
- 순차적으로 2,3 Broker도 이와 동일한 방법으로 업그레이드 진행
### 8.2.3 브로커 설정 변경
- 브로커 프로토콜 및 메시지 포맷 버전을 변경한다.
- server.properties 내 옵션을 삭제하면 따로 명시하지 않으면 기본값이 적용된다.(Recommended)
- 브로커 한 대씩 재시작
### 8.2.4 버전 업그레이드 작업 시 주의사항
- 사용량이 적은 시간대를 골라 업그레이드 작업을 실시
- Producer의 ack=1 옵션을 사용하는 경우 카프카의 롤링 재시작으로 인해 일부 메시지가 손실될 수 있음을 주의
    - 업그레이드 전 프로듀서의 옵션에 대해서도 면밀히 검토한 후 버전 업그레이드 실시

## 8.3 카프카의 확장
- 카프카는 안전하고 손쉽게 확장할 수 있도록 디자인
- 카프카 확장 시, 브로커를 추가해줘야함
    - server.properties에 broker.id를 설정하여 새로 추가되는 브로커에 대해 고유한 broker.id를 부여해야 하므로, 기존과 중복되지 않는 신규 ID 번호인 4로 설정
- 카프카를 확장하여도 기존의 토픽과 파티션들은 새로 추가된 브로커로 이동하지 않는다.
    - 관리자가 수작업으로 토픽의 파티션들을 고르게 분산시켜야함
- 카프카 확장 이후 새로 추가된 토픽과 파티션들은 자동으로 분산
- 부하 분산이 목적인 경우에 브로커만 추가했다고 끝나는 것이 아니라 새롭게 추가된 브로커에도 기존의 파티션들을 할당해야한다.
### 8.3.1 브로커 부하 분산
- 카프카에서 제공하는 kafka-reassign-partitions.sh라는 도구를 이용하면 파티션을 이동할 수 있다.

``` 
토픽을 정의한 JSON 파일
{"topics":
    [{"topic": "peter-scaleout1"},{"topic: "peter-scaleout2""}],
    "version":1
}
```

``` 
/usr/local/kafka/bin/kafka-reassign-partitions.sh --bootstrap-server peter-kafka01.foo.bar:9092 --generate --topics-to-move-json-file reassgin-partitions-topic.json --broker-list "1,2,3,4"
```
- 제안된 파티션 배치 json 파일이 생성됨
- 제안된 json 파일로 실제 파티션을 브로커에 재분배한다.
``` 
/usr/local/kafka/bin/kafka-reassign-partitions.sh --bootstrap-server peter-kafka01.foo.bar:9092 --reassignment-json-file move.json --execute
```
- 실제로는 기존 보로커들이 갖고 있던 파티션들은 자동으로 분산되지 않는다.
- 신규 브로커가 추가된 이후에 생성하는 토픽들은 신규 브로커를 비롯해 파티션들을 재배치한다.
- 수동으로 분산 작업을 진행
- 실제 운영 환경에서 일부 토픽들의 배치가 균형이 맞지 않는 경우 브로커들에게 고르게 파티션을 재배치한다면, 효율적으로 브로커의 리소스를 사용할 수 있다.
### 8.3.2 분산 배치 작업 시 주의사항
- 카프카 사용이 낮은 시간에 작업
- 실제 파티션이 이동하는 것이 아니라 브로커 내부적으로 리플레이케이션하는 동작이 일어난다.
    - 이동 대상 파티션을 목적지 브로커에 리플리케이션
    - 리플레케이션 완료 후 이동하기 전 브로커에 위치한 파티션은 삭제
    - 결과적으로 마치 이동한 것으로 보이지만, 내부적으로는 리플리케이션 동작이 일어난다.
- 리플리케이션으로 인한 네트워크 트래픽 사용량도 급증해 서버 관리자나 네트워크 관리자에게 알람이 갈 수 있다.
- 불필요한 메시지들을 재배치하지 않음
    - Example)보관주기
- 파티션 재배치 작업 시 여러 개의 토픽을 동시에 진행하지 않고, 단 하나의 토픽으로 진행함


<hr>

# Q&A
- Producer의 ack=1 옵션 사용 시, 카프카 롤링 재시작으로 인해 일부 메시지가 손실될 수 있다고 하는데 Why?
- 리플레케이션 시 리소스 어떤식으로 발생하는지 다시 한번 복습하기



